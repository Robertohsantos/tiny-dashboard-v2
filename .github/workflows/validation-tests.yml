name: Validation Tests

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/modules/**/hooks/data/**/*.validated.ts'
      - 'src/modules/**/services/**/*.validated.ts'
      - 'src/modules/**/schemas/**/*.ts'
      - 'src/modules/core/utils/validation.ts'
      - 'src/modules/**/hooks/data/**/*-switch.ts'
      - '.github/workflows/validation-tests.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'src/modules/**/hooks/data/**/*.validated.ts'
      - 'src/modules/**/services/**/*.validated.ts'
      - 'src/modules/**/schemas/**/*.ts'
      - 'src/modules/core/utils/validation.ts'
      - 'src/modules/**/hooks/data/**/*-switch.ts'
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run performance impact tests'
        required: false
        default: 'true'
        type: boolean

env:
  NODE_VERSION: '20'
  VALIDATION_ENABLED: 'true'

jobs:
  # Job 1: Validation Unit Tests
  validation-unit-tests:
    name: Validation Unit Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Run validation unit tests
        run: |
          npm run test -- \
            --testPathPattern=".*\\.validated\\.test\\.(ts|tsx)$" \
            --coverage \
            --coverageDirectory=coverage/validation-unit
        env:
          CI: true
          NEXT_PUBLIC_VALIDATION_ENABLED: true

      - name: Check validation coverage
        run: |
          COVERAGE=$(npx nyc report --reporter=json-summary | jq '.total.lines.pct')
          echo "Validation test coverage: ${COVERAGE}%"
          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "âš ï¸ Warning: Validation test coverage is below 80%"
            exit 1
          fi

      - name: Upload validation coverage
        uses: actions/upload-artifact@v4
        with:
          name: validation-coverage
          path: coverage/validation-unit/
          retention-days: 7

  # Job 2: Validation Integration Tests
  validation-integration-tests:
    name: Validation Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Setup database
        run: |
          npx prisma migrate reset --force
          npx prisma db seed
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test

      - name: Run validation integration tests
        run: |
          npm run test:integration -- \
            --testPathPattern=".*hooks.*\\.integration\\.test\\.(ts|tsx)$" \
            --forceExit
        env:
          CI: true
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          NEXT_PUBLIC_VALIDATION_ENABLED: true
          VALIDATION_ERROR_THRESHOLD: 10
          VALIDATION_PERFORMANCE_THRESHOLD: 100

      - name: Test validation fallback mechanism
        run: |
          echo "Testing validation fallback with forced errors..."
          FORCE_VALIDATION_ERROR=true npm run test:integration -- \
            --testNamePattern="fallback" \
            --forceExit

      - name: Test auto-rollback trigger
        run: |
          echo "Testing auto-rollback with threshold breach..."
          VALIDATION_ERROR_THRESHOLD=1 npm run test:integration -- \
            --testNamePattern="rollback" \
            --forceExit

  # Job 3: Performance Impact Measurement
  performance-impact:
    name: Performance Impact Measurement
    runs-on: ubuntu-latest
    if: github.event.inputs.run_performance_tests == 'true' || github.event_name == 'push'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Build application
        run: npm run build
        env:
          NEXT_PUBLIC_BASE_URL: http://localhost:3000
          DATABASE_URL: postgresql://test:test@localhost:5432/test

      - name: Measure performance - Original hooks
        run: |
          echo "Starting server with original hooks..."
          NEXT_PUBLIC_VALIDATION_ENABLED=false npm run start &
          SERVER_PID=$!
          npx wait-on http://localhost:3000 --timeout 60000
          
          echo "Running performance tests..."
          npx lighthouse http://localhost:3000/dashboard-vendas \
            --output=json \
            --output-path=./lighthouse-original.json \
            --only-categories=performance \
            --throttling-method=provided \
            --chrome-flags="--headless"
          
          kill $SERVER_PID
          wait $SERVER_PID 2>/dev/null || true

      - name: Measure performance - Validated hooks
        run: |
          echo "Starting server with validated hooks..."
          NEXT_PUBLIC_VALIDATION_ENABLED=true npm run start &
          SERVER_PID=$!
          npx wait-on http://localhost:3000 --timeout 60000
          
          echo "Running performance tests..."
          npx lighthouse http://localhost:3000/dashboard-vendas \
            --output=json \
            --output-path=./lighthouse-validated.json \
            --only-categories=performance \
            --throttling-method=provided \
            --chrome-flags="--headless"
          
          kill $SERVER_PID
          wait $SERVER_PID 2>/dev/null || true

      - name: Compare performance metrics
        run: |
          node << 'EOF'
          const fs = require('fs');
          
          const original = JSON.parse(fs.readFileSync('./lighthouse-original.json'));
          const validated = JSON.parse(fs.readFileSync('./lighthouse-validated.json'));
          
          const originalPerf = original.categories.performance.score * 100;
          const validatedPerf = validated.categories.performance.score * 100;
          const impact = validatedPerf - originalPerf;
          
          console.log(`ðŸ“Š Performance Comparison:`);
          console.log(`Original hooks: ${originalPerf.toFixed(1)}%`);
          console.log(`Validated hooks: ${validatedPerf.toFixed(1)}%`);
          console.log(`Impact: ${impact > 0 ? '+' : ''}${impact.toFixed(1)}%`);
          
          // Key metrics comparison
          const metrics = ['first-contentful-paint', 'largest-contentful-paint', 'total-blocking-time'];
          
          console.log(`\nðŸ“ˆ Key Metrics:`);
          metrics.forEach(metric => {
            const origValue = original.audits[metric].numericValue;
            const valValue = validated.audits[metric].numericValue;
            const diff = ((valValue - origValue) / origValue * 100).toFixed(1);
            console.log(`${metric}: ${diff > 0 ? '+' : ''}${diff}%`);
          });
          
          // Fail if performance degrades more than 5%
          if (impact < -5) {
            console.error(`\nâŒ Performance regression detected: ${impact.toFixed(1)}%`);
            process.exit(1);
          } else if (impact < -2) {
            console.warn(`\nâš ï¸ Minor performance impact: ${impact.toFixed(1)}%`);
          } else {
            console.log(`\nâœ… Performance impact acceptable`);
          }
          
          // Save comparison report
          const report = {
            timestamp: new Date().toISOString(),
            original: originalPerf,
            validated: validatedPerf,
            impact: impact,
            metrics: {}
          };
          
          metrics.forEach(metric => {
            report.metrics[metric] = {
              original: original.audits[metric].numericValue,
              validated: validated.audits[metric].numericValue,
              diff: validated.audits[metric].numericValue - original.audits[metric].numericValue
            };
          });
          
          fs.writeFileSync('./performance-comparison.json', JSON.stringify(report, null, 2));
          EOF

      - name: Upload performance reports
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports
          path: |
            lighthouse-*.json
            performance-comparison.json
          retention-days: 30

      - name: Comment PR with performance impact
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('./performance-comparison.json'));
            
            const impactEmoji = report.impact > 0 ? 'ðŸ“ˆ' : report.impact < -2 ? 'ðŸ“‰' : 'âž¡ï¸';
            const statusEmoji = report.impact < -5 ? 'âŒ' : report.impact < -2 ? 'âš ï¸' : 'âœ…';
            
            const comment = `### ${statusEmoji} Validation Hooks Performance Impact
            
            ${impactEmoji} **Overall Impact: ${report.impact > 0 ? '+' : ''}${report.impact.toFixed(1)}%**
            
            | Metric | Original | Validated | Difference |
            |--------|----------|-----------|------------|
            | Performance Score | ${report.original.toFixed(1)}% | ${report.validated.toFixed(1)}% | ${report.impact > 0 ? '+' : ''}${report.impact.toFixed(1)}% |
            | First Contentful Paint | ${report.metrics['first-contentful-paint'].original.toFixed(0)}ms | ${report.metrics['first-contentful-paint'].validated.toFixed(0)}ms | ${report.metrics['first-contentful-paint'].diff > 0 ? '+' : ''}${report.metrics['first-contentful-paint'].diff.toFixed(0)}ms |
            | Largest Contentful Paint | ${report.metrics['largest-contentful-paint'].original.toFixed(0)}ms | ${report.metrics['largest-contentful-paint'].validated.toFixed(0)}ms | ${report.metrics['largest-contentful-paint'].diff > 0 ? '+' : ''}${report.metrics['largest-contentful-paint'].diff.toFixed(0)}ms |
            | Total Blocking Time | ${report.metrics['total-blocking-time'].original.toFixed(0)}ms | ${report.metrics['total-blocking-time'].validated.toFixed(0)}ms | ${report.metrics['total-blocking-time'].diff > 0 ? '+' : ''}${report.metrics['total-blocking-time'].diff.toFixed(0)}ms |
            
            ${report.impact < -5 ? '**âš ï¸ Action Required:** Performance regression exceeds 5% threshold. Please optimize the validation logic.' : 
              report.impact < -2 ? '**ðŸ“ Note:** Minor performance impact detected. Consider optimization if possible.' :
              '**âœ… Good to go:** Performance impact is within acceptable limits.'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Job 4: Validation Error Monitoring
  validation-monitoring:
    name: Validation Error Monitoring
    runs-on: ubuntu-latest
    needs: [validation-unit-tests, validation-integration-tests]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Test telemetry endpoints
        run: |
          echo "Testing validation telemetry endpoints..."
          
          # Start the server
          npm run dev &
          SERVER_PID=$!
          npx wait-on http://localhost:3000 --timeout 60000
          
          # Test validation error reporting
          curl -X POST http://localhost:3000/api/monitoring/validation \
            -H "Content-Type: application/json" \
            -d '{
              "hookName": "useDashboardMetrics",
              "errorType": "validation_failed",
              "errorDetails": {"test": true},
              "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"
            }' || exit 1
          
          # Test rollback alert
          curl -X POST http://localhost:3000/api/monitoring/rollback-alert \
            -H "Content-Type: application/json" \
            -d '{
              "message": "Test rollback alert",
              "severity": "high",
              "details": {"test": true}
            }' || exit 1
          
          kill $SERVER_PID
          wait $SERVER_PID 2>/dev/null || true
          
          echo "âœ… Telemetry endpoints working correctly"

  # Job 5: Validation CI Status
  validation-ci-status:
    name: Validation CI Status
    runs-on: ubuntu-latest
    needs: [validation-unit-tests, validation-integration-tests, performance-impact, validation-monitoring]
    if: always()
    
    steps:
      - name: Check Validation CI Status
        run: |
          if [[ "${{ needs.validation-unit-tests.result }}" != "success" || 
                "${{ needs.validation-integration-tests.result }}" != "success" || 
                "${{ needs.validation-monitoring.result }}" != "success" ]]; then
            echo "âŒ Validation CI failed"
            exit 1
          fi
          
          if [[ "${{ needs.performance-impact.result }}" == "failure" ]]; then
            echo "âŒ Performance regression detected"
            exit 1
          fi
          
          echo "âœ… All validation checks passed successfully!"
          echo "Ready for deployment with validated hooks enabled"

      - name: Generate validation report
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          echo "# Validation Hooks Status Report" > validation-report.md
          echo "**Date:** $(date -u +"%Y-%m-%d %H:%M UTC")" >> validation-report.md
          echo "**Commit:** ${{ github.sha }}" >> validation-report.md
          echo "" >> validation-report.md
          echo "## Test Results" >> validation-report.md
          echo "- Unit Tests: ${{ needs.validation-unit-tests.result }}" >> validation-report.md
          echo "- Integration Tests: ${{ needs.validation-integration-tests.result }}" >> validation-report.md
          echo "- Performance Impact: ${{ needs.performance-impact.result }}" >> validation-report.md
          echo "- Monitoring Tests: ${{ needs.validation-monitoring.result }}" >> validation-report.md
          echo "" >> validation-report.md
          echo "## Deployment Readiness" >> validation-report.md
          echo "âœ… Validated hooks are ready for production deployment" >> validation-report.md

      - name: Upload validation report
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: validation-report.md
          retention-days: 90